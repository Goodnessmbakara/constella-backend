from datetime import datetime
from typing import Dict, Any, List, Optional

import json
import os

from fastapi import APIRouter, HTTPException, WebSocket, WebSocketDisconnect
from pydantic import BaseModel, Field
from bson.objectid import ObjectId

from db.mongodb import db
from ai.ai_api import openai_structured_output, create_json_schema
from cerebras.cloud.sdk import Cerebras
from ai.autoloop.loop_tools_defs import get_autoloop_tools
from ai.autoloop.loop_tools_impls import AVAILABLE_TOOLS
import re

router = APIRouter(
	prefix="/horizon/autoloop",
	tags=["horizon_autoloop"],
)

class CreateAutoloopRequest(BaseModel):
	tenant_name: str = Field(..., description="Tenant identifier")
	goal: str


@router.post("/create")
def create_autoloop_task(req: CreateAutoloopRequest):
	"""
	1. Create a plan for the autoloop task to then pass to the looper agent
	"""

	# TODO: would make this pass from frontend
	tools = [
		"search_papers",
		"read_full_paper_content"
	]

	prompt = f"""You are a reinforcement learning agent about to embark towards the goal of: {req.goal}
Think of all the metrics you need to track as well all the actions you would need to take towards it.
Also think of all the data you should collect as you go to give the user a comprehensive, well thought out response back at the end.

This goal will be accomplished through various API calls to the internet. The tools that are available to you are:
{', '.join(tools)}

With this in mind, generate the required fields for tracking progress towards this goal."""

	# Define the schema properties
	properties = {
		"quantifiable_metrics_to_measure_towards_goal": {
			"type": "string",
			"description": "Detailed description of metrics that can be measured to track progress"
		},
		"structure_of_all_data_fields_to_track_so_far": {
			"type": "object",
			"description": "JSON object defining all data fields that should be tracked during the autoloop execution",
			"additionalProperties": True
		}
	}

	# Create the JSON schema using helper function
	response_format = create_json_schema(
		name="autoloop_planning",
		properties=properties,
		required_fields=["quantifiable_metrics_to_measure_towards_goal", "structure_of_all_data_fields_to_track_so_far"]
	)

	# Prepare messages for OpenAI
	messages = [
		{"role": "user", "content": prompt}
	]

	# Call OpenAI with structured output
	result = openai_structured_output(
		messages=messages,
		response_format=response_format,
		max_tokens=1500,
		temperature=0.7
	)

	# Print the result
	print("Structured Output Result:")
	print(result)

	return result


class AutoloopTask(BaseModel):
	tenant_name: str = Field(..., description="Tenant identifier")
	goal: str
	plan: Dict[str, Any] = Field(..., description="Plan generated by the AI agent")
	tracking_data: Dict[str, Any] = Field(..., description="Tracking data generated by the AI agent")

# ---------------------------------
# WebSocket looper using Cerebras
# ---------------------------------

_cerebras_client: Optional[Cerebras] = None

def _get_cerebras_client() -> Cerebras:
	global _cerebras_client
	if _cerebras_client is None:
		_cerebras_client = Cerebras(api_key=os.environ.get("CEREBRAS_API_KEY"))
	return _cerebras_client

def _build_system_prompt(goal: str, plan: Dict[str, Any], tracking_data: Dict[str, Any], explainer_nodes: List[Dict[str, Any]] = None) -> str:
	return (
		"You are an autonomous research assistant operating a closed-loop tool execution cycle to achieve the user's goal.\n"
		"- Always decide whether to call tools based on the current plan and tracking_data.\n"
		"- After each tool call, if internal state changed, you MUST call update_tracking_data with the exact delta.\n"
		"- Repeat tool calls as needed until you can produce a concise final answer without more tools.\n"
		"- When you are done, return a final message with your conclusions and set no tool_calls.\n\n"
		"- You MUST call tool calls and keep going towards the goal given to you until the tracking data reflects a completion of the goal.\n\n"
		"- You MUST track explainer node cards that show your current thinking and progress in depth and detail with connections"
		f"Goal:\n{goal}\n\n"
		f"Plan (JSON):\n{json.dumps(plan, ensure_ascii=False)}\n\n"
		f"Current tracking_data (JSON):\n{json.dumps(tracking_data, ensure_ascii=False)}\n"
	)

def _apply_property_updates_to_tracking_data(tracking_data: Dict[str, Any], updates: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
	for property_name, update_spec in updates.items():
		update_type = update_spec.get("typeOfUpdate")
		update_value = update_spec.get("updateValue")

		if update_type == "CHANGE_VALUE":
			tracking_data[property_name] = update_value
		elif update_type == "ARRAY_PUSH_VALUE":
			existing = tracking_data.get(property_name)
			if not isinstance(existing, list):
				existing = [] if existing is None else [existing]
			existing.append(update_value)
			tracking_data[property_name] = existing
		elif update_type == "ARRAY_REMOVE_VALUE":
			existing = tracking_data.get(property_name, [])
			if isinstance(existing, list):
				tracking_data[property_name] = [v for v in existing if v != update_value]
		else:
			# Unknown update type; ignore
			pass
	return tracking_data

async def _run_cerebras_tool_call(
	tool_call,
	messages: List[Dict[str, Any]],
	tracking_data: Dict[str, Any],
	websocket: WebSocket,
	explainer_nodes: List[Dict[str, Any]],
):
	function_call = tool_call.function
	fname = function_call.name
	args = json.loads(function_call.arguments or "{}")

	print(f"[AUTOLOOP] Executing function: {fname}")

	await websocket.send_json({
		"type": "tool_call",
		"tool": fname,
		"arguments": args,
	})

	# Execute the tool implementation
	if fname not in AVAILABLE_TOOLS:
		result = {"success": False, "error": f"Unknown tool: {fname}"}
	else:
		try:
			if fname in ("create_root_explainer_card", "add_card_body_item"):
				result = AVAILABLE_TOOLS[fname](**args, explainer_nodes=explainer_nodes)
			else:
				result = AVAILABLE_TOOLS[fname](**args)
		except Exception as e:
			result = {"success": False, "error": f"Execution error: {str(e)}"}

	print(f"[AUTOLOOP] Function {fname} result: {result}")

	# Special handling: apply updates to in-memory tracking_data
	if fname in ("update_tracking_data", "update_internal_state"):
		updates = args.get("property_updates", {})
		tracking_data = _apply_property_updates_to_tracking_data(tracking_data, updates)
		# Ensure tool result carries the updated state back
		if isinstance(result, dict):
			result.setdefault("success", True)
			result["tracking_data"] = tracking_data

		await websocket.send_json({
			"type": "tracking_data_updated",
			"tracking_data": tracking_data,
		})

	# Feed result back to model
	messages.append({
		"role": "tool",
		"content": json.dumps(result),
		"tool_call_id": tool_call.id,
	})

	await websocket.send_json({
		"type": "tool_result",
		"tool": fname,
		"result": result,
	})

	# Notify explainer nodes updates after relevant tools
	if fname in ("create_root_explainer_card", "add_card_body_item"):
		await websocket.send_json({
			"type": "explainer_nodes_updated",
			"explainer_nodes": explainer_nodes,
		})

	return tracking_data

@router.websocket("/looper/ws")
async def looper_ws(websocket: WebSocket):
	await websocket.accept()
	try:
		init = await websocket.receive_json()
		# Expecting: { tenant_name, goal, plan, tracking_data, model? }
		tenant_name: str = init.get("tenant_name")
		goal: str = init.get("goal")
		plan: Dict[str, Any] = init.get("plan", {})
		tracking_data: Dict[str, Any] = init.get("tracking_data", {})
		model = "qwen-3-235b-a22b-instruct-2507"

		explainer_nodes: List[Dict[str, Any]] = []

		tools = get_autoloop_tools()

		messages: List[Dict[str, Any]] = []
		# Seed system prompt with goal, plan, and tracking_data
		system_prompt = _build_system_prompt(goal, plan, tracking_data)
		messages.append({"role": "system", "content": system_prompt})
		# Seed with an initial user nudge
		messages.append({
			"role": "user",
			"content": (
				"Begin working towards the goal. Use tools as needed. "
				"Always keep tracking_data updated via update_tracking_data."
			)
		})

		client = _get_cerebras_client()

		while True:
			create_kwargs = {
				"model": model,
				"messages": messages,
				"tools": tools,
			}
			if model == "llama-4-scout-17b-16e-instruct":
				create_kwargs["parallel_tool_calls"] = False

			resp = client.chat.completions.create(**create_kwargs)
			assistant_msg = resp.choices[0].message

			# Log the AI call output
			print(f"[AUTOLOOP] AI Call Output: {resp}")

			# Stream assistant content (if any)
			if assistant_msg.content:
				print(f"[AUTOLOOP] Assistant Message Content: {assistant_msg.content}")
				await websocket.send_json({
					"type": "assistant_message",
					"content": assistant_msg.content,
				})

			# If no tool calls, we are done
			if not assistant_msg.tool_calls:
				await websocket.send_json({
					"type": "final",
					"content": assistant_msg.content,
				})
				break

			# Log assistant tool calls
			print(f"[AUTOLOOP] Assistant Tool Calls: {assistant_msg.tool_calls}")

			# Save the assistant turn
			messages.append(assistant_msg.model_dump())

			# Execute tools requested by assistant
			for tool_call in assistant_msg.tool_calls:
				tracking_data = await _run_cerebras_tool_call(
					tool_call=tool_call,
					messages=messages,
					tracking_data=tracking_data,
					websocket=websocket,
					explainer_nodes=explainer_nodes,
				)

			# Refresh system prompt with updated plan/tracking_data before next turn
			messages[0]["content"] = _build_system_prompt(goal, plan, tracking_data, explainer_nodes)

		await websocket.close()

	except WebSocketDisconnect:
		# Client disconnected; nothing to do
		return
	except Exception as e:
		try:
			await websocket.send_json({"type": "error", "error": str(e)})
		except Exception:
			pass
		try:
			await websocket.close()
		except Exception:
			pass


@router.get("/task/{task_id}")
def get_task_status(task_id: str):
	"""Get the status and results of a research task"""
	try:
		if db is None:
			raise HTTPException(status_code=500, detail="Database connection not available")

		task = db.autoloop_tasks.find_one({"_id": ObjectId(task_id)})
		if not task:
			raise HTTPException(status_code=404, detail="Task not found")

		# Convert ObjectId to string for JSON serialization
		task["_id"] = str(task["_id"])
		return task

	except Exception as e:
		raise HTTPException(status_code=500, detail=f"Error retrieving task: {str(e)}")
